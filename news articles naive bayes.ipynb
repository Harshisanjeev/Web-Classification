{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/k7-user0/Desktop/annotated'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k7-user0\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k7-user0/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k7-user0/Desktop/annotated\n"
     ]
    }
   ],
   "source": [
    "cd annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Math\n",
    "import math\n",
    "\n",
    "# Plot imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# For evaluating our ML results\n",
    "from sklearn import metrics\n",
    "\n",
    "# Dataset Import\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = os.listdir(\"/home/k7-user0/Desktop/annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n",
      "\n",
      "Iteration\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "i=1\n",
    "notcontentlist = []\n",
    "headlinelist = []\n",
    "fulltextlist = []\n",
    "supplementallist = []\n",
    "relatedcontentlist = []\n",
    "commentslist = []\n",
    "for names in items[:400]:\n",
    "    try:\n",
    "        \n",
    "        print(\"\\nIteration\")\n",
    "\n",
    "        num=1\n",
    "\n",
    "        string = names\n",
    "        codecs.open(string,\"r\")\n",
    "        soup = BeautifulSoup(open(string), \"html.parser\")\n",
    "\n",
    "\n",
    "        notcontent = soup.find_all(\"span\",attrs = {\"class\":\"x-nc-sel0\"})\n",
    "        #print(type(notcontent))\n",
    "        headline = soup.find_all(\"span\", attrs = {\"class\":\"x-nc-sel1\"})\n",
    "\n",
    "        fulltext = soup.find_all(\"span\", attrs = {\"class\":\"x-nc-sel2\"})\n",
    "\n",
    "        supplemental = soup.find_all(\"span\", attrs = {\"class\":\"x-nc-sel3\"})\n",
    "\n",
    "        relatedcontent = soup.find_all(\"span\", attrs = {\"class\":\"x-nc-sel4\"})\n",
    "\n",
    "        comments = soup.find_all(\"span\", attrs = {\"class\":\"x-nc-sel5\"})\n",
    "        \n",
    "        for i in notcontent:\n",
    "            notcontentlist.append(i.text)\n",
    "            \n",
    "        for i in headline:\n",
    "            headlinelist.append(i.text)\n",
    "            \n",
    "        for i in fulltext:\n",
    "            fulltextlist.append(i.text)\n",
    "            \n",
    "        for i in supplemental:\n",
    "            supplementallist.append(i.text)\n",
    "            \n",
    "        for i in relatedcontent:\n",
    "            relatedcontentlist.append(i.text)\n",
    "            \n",
    "        for i in comments:\n",
    "            commentslist.append(i.text)\n",
    "        '''\n",
    "        print(\"hi\")\n",
    "        for j in headline:\n",
    "            headlinelist.append(j.text)\n",
    "        print(\"error here1\")\n",
    "        for k in fulltext:\n",
    "            fulltextlist.append(k.text)\n",
    "        print(\"error here2\")\n",
    "        for x in supplemental:\n",
    "            supplementallist.append(x.text)\n",
    "        print(\"error here3\")\n",
    "        for y in relatedcontent:\n",
    "            relatedcontentlist.append(y.text)\n",
    "        print(\"error here4\")\n",
    "        for z in comments:\n",
    "            commentslist.append(z.text)\n",
    "        print(\"error here5\")\n",
    "        #notcontent\n",
    "        '''\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "\n",
    "res1 = \"\".join(notcontentlist)\n",
    "res2 = \"\".join(headlinelist)\n",
    "res3 = \"\".join(fulltextlist)\n",
    "res4 = \"\".join(supplementallist)\n",
    "res5 = \"\".join(relatedcontentlist)\n",
    "res6 = \"\".join(commentslist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tags:',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\narts-and-entertainment\\n',\n",
       " '\\n',\n",
       " 'arts-and-entertainment',\n",
       " 'arts-and-entertainment',\n",
       " '\\n',\n",
       " '\\n',\n",
       " ',']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notcontentlist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "       #notcontent\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform([res1])\n",
    "\n",
    "num = x.todense().shape[1]\n",
    "\n",
    "df1=pd.DataFrame(x.todense(),columns= list(range(1,num+1)))\n",
    "df1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform([res2])\n",
    "\n",
    "        #print(x.todense().shape)\n",
    "num2 = x.todense().shape[1]\n",
    "vocab2 = v.vocabulary_\n",
    "        #print(vocab2)\n",
    "\n",
    "df2=pd.DataFrame(x.todense(),columns= list(range(1,num2+1)))\n",
    "df2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform([res3])\n",
    "\n",
    "        #print(x.todense().shape)\n",
    "num3 = x.todense().shape[1]\n",
    "vocab2 = v.vocabulary_\n",
    "        #print(vocab2)\n",
    "\n",
    "df3=pd.DataFrame(x.todense(),columns= list(range(1,num3+1)))\n",
    "df3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform([res4])\n",
    "\n",
    "        #print(x.todense().shape)\n",
    "num4 = x.todense().shape[1]\n",
    "vocab2 = v.vocabulary_\n",
    "        #print(vocab2)\n",
    "\n",
    "df4=pd.DataFrame(x.todense(),columns= list(range(1,num4+1)))\n",
    "df4.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    v = TfidfVectorizer()\n",
    "    x = v.fit_transform([res5])\n",
    "\n",
    "            #print(x.todense().shape)\n",
    "    num5 = x.todense().shape[1]\n",
    "    vocab5 = v.vocabulary_\n",
    "            #print(vocab5)\n",
    "\n",
    "    df5=pd.DataFrame(x.todense(),columns= list(range(1,num5+1)))\n",
    "    df5.drop_duplicates(inplace=True)\n",
    "            #df5.shape\n",
    "except:\n",
    "    num5 = 0\n",
    "            #vocab5 = v.vocabulary_\n",
    "            #print(vocab5)\n",
    "    df5=pd.DataFrame(columns= list(range(1,num5+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    v = TfidfVectorizer()\n",
    "    x=0\n",
    "    x = v.fit_transform([i.text for i in comments if None != i])\n",
    "\n",
    "            #print(x.todense().shape)\n",
    "    num6 = x.todense().shape[1]\n",
    "    vocab5 = v.vocabulary_\n",
    "            #print(vocab5)\n",
    "    df6=pd.DataFrame(x.todense(),columns= list(range(1,num6+1)))\n",
    "            #df6.drop_duplicates(inplace=True)\n",
    "            #df6.shape\n",
    "except:\n",
    "            #print(\"error\")\n",
    "            #print(x)\n",
    "    num6 = 0\n",
    "            #vocab5 = v.vocabulary_\n",
    "            #print(vocab5)\n",
    "    df6=pd.DataFrame(columns= list(range(1,num6+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rows1 = len(df1.axes[0])\n",
    "except:\n",
    "    rows1 = 0\n",
    "try:\n",
    "    rows2 = len(df2.axes[0])\n",
    "except:\n",
    "    rows2 = 0\n",
    "try:\n",
    "    rows3 = len(df3.axes[0])\n",
    "except:\n",
    "    rows3 = 0\n",
    "try:\n",
    "    rows4 = len(df4.axes[0])\n",
    "except:\n",
    "    rows4 = 0\n",
    "try:\n",
    "    rows5 = len(df5.axes[0])\n",
    "except:\n",
    "    rows5 = 0\n",
    "try:\n",
    "    rows6 = len(df6.axes[0])\n",
    "except:\n",
    "    rows6 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Not content\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "summ = rows2+rows3+rows4+rows5+rows6\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df1 is not None:\n",
    "    for i in range(rows1):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows1, summ+rows1):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows1):\n",
    "        dataframe.loc[i] = 0\n",
    "\n",
    "try:\n",
    "    tempdf1 = pd.concat([df1,df2], axis =0)\n",
    "except:\n",
    "    tempdf1 = df1\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df3], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nNot content\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heading\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df2,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df2\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df3], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "#finaldf.shape\n",
    "\n",
    "summ = rows1+rows3+rows4+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df2 is not None:\n",
    "\n",
    "    for i in range(rows2):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows2, summ+rows2):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows2):\n",
    "        dataframe.loc[i] = 0\n",
    "#dataframe.shape\n",
    "\n",
    "#For headline\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state = 5)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nHeading\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1         2         3         4         5         6         7      \\\n",
      "0  0.012255  0.226727  0.012255  0.012255  0.004596  0.019915  0.003064   \n",
      "0  0.000809  0.007487  0.000051  0.000051  0.000051  0.000051  0.000051   \n",
      "\n",
      "      8         9         10       ...        17324     17325     17326  \\\n",
      "0  0.001532  0.015319  0.243578    ...     0.000051  0.000051  0.000051   \n",
      "0  0.000051  0.000708  0.000051    ...     0.000051  0.000051  0.000051   \n",
      "\n",
      "      17327     17328     17329     17330     17331     17332     17333  \n",
      "0  0.000051  0.000152  0.002681  0.000051  0.000101  0.000354  0.000051  \n",
      "0  0.000051  0.000152  0.002681  0.000051  0.000101  0.000354  0.000051  \n",
      "\n",
      "[2 rows x 17333 columns]\n",
      "\n",
      "Fulltext\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df3,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df3\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "summ = rows1+rows2+rows4+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df3 is not None:\n",
    "    for i in range(rows3):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows3, summ+rows3):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows3):\n",
    "        dataframe.loc[i]=0\n",
    "#dataframe.shape\n",
    "\n",
    "#For fulltext\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25, random_state = 5)\n",
    "print(X_test[:10])\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nFulltext\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "the xarray library is not installed\nyou can install via conda\nconda install xarray\nor via pip\npip install xarray\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2335\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-48b6145542cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;31m# Give a nice error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m             raise ImportError(\"the xarray library is not installed\\n\"\n\u001b[0m\u001b[1;32m   2339\u001b[0m                               \u001b[0;34m\"you can install via conda\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m                               \u001b[0;34m\"conda install xarray\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: the xarray library is not installed\nyou can install via conda\nconda install xarray\nor via pip\npip install xarray\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "supplemental\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df4,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df4\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df3], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "\n",
    "\n",
    "summ = rows1+rows2+rows3+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df4 is not None:\n",
    "    for i in range(rows4):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows4, summ+rows4):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows4):\n",
    "        dataframe.loc[i]=0\n",
    "\n",
    "#dataframe.shape\n",
    "\n",
    "#For supplemental\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=2)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nsupplemental\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Related Content\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    tempdf1 = pd.concat([df5,df1], axis =0)\n",
    "    #print(\"try\")\n",
    "except:\n",
    "    tempdf1 = df5\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df3], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df4], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "index = finaldf.shape[0]\n",
    "#print(index)\n",
    "\n",
    "summ = rows1+rows2+rows3+rows4+rows6\n",
    "#print(summ)\n",
    "#print(rows5)\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df5 is not None:\n",
    "    #print(\"im in\")\n",
    "    if rows5 is 0:\n",
    "        for i in range(index):\n",
    "            dataframe.loc[i] = 0\n",
    "    else:\n",
    "        for i in range(rows5):\n",
    "            dataframe.loc[i] = 1\n",
    "        for j in range(rows5, summ+rows5):\n",
    "            dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows5+1):\n",
    "        dataframe.loc[i]=0\n",
    "#print(dataframe)\n",
    "\n",
    "#For related content\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "#print(X.shape)\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state=4)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nRelated Content\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 17333), (2, 17333))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comments\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if df6 != None:\n",
    "        tempdf1 = pd.concat([df6,df1], axis =0)\n",
    "except:\n",
    "    try:\n",
    "        tempdf1 = df6\n",
    "    except:\n",
    "        tempdf1 = df1\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df3], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df4], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df5], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "index = finaldf.shape[0]\n",
    "\n",
    "summ = rows1+rows2+rows3+rows4+rows5\n",
    "i=0\n",
    "#print(summ)\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df6 is not None:\n",
    "    if rows6 is 0:\n",
    "        #print(\"im in\")\n",
    "        for i in range(index):\n",
    "            dataframe.loc[i] = 0\n",
    "    else:\n",
    "        for i in range(rows6+1) and df6:\n",
    "            dataframe.loc[i] = 1\n",
    "        for j in range(rows6+1, summ+rows6+1):\n",
    "            dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows6):\n",
    "        dataframe.loc[i]=0\n",
    "#print(dataframe.shape)\n",
    "\n",
    "#For comments\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "#print(X.shape)\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "#print(Y.shape)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nComments\")\n",
    "print(metrics.accuracy_score(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df2,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df2\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df3], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "#finaldf.shape\n",
    "\n",
    "summ = rows1+rows3+rows4+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df2 is not None:\n",
    "\n",
    "    for i in range(rows2):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows2, summ+rows2):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows2):\n",
    "        dataframe.loc[i] = 0\n",
    "#dataframe.shape\n",
    "\n",
    "#For headline\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state = 5)\n",
    "\n",
    "#model.fit(X_train, Y_train)\n",
    "\n",
    "#predicted = model.predict(X_test)\n",
    "\n",
    "#expected = Y_test\n",
    "#print(\"\\nHeading\")\n",
    "#print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "# 4. make class predictions for X_test_dtm\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = rows2+rows3+rows4+rows5+rows6\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df1 is not None:\n",
    "    for i in range(rows1):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows1, summ+rows1):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows1):\n",
    "        dataframe.loc[i] = 0\n",
    "\n",
    "try:\n",
    "    tempdf1 = pd.concat([df1,df2], axis =0)\n",
    "except:\n",
    "    tempdf1 = df1\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df3], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.39 ms, sys: 0 ns, total: 6.39 ms\n",
      "Wall time: 6.15 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "# 4. make class predictions for X_test_dtm\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "supplemental\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df4,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df4\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df3], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "\n",
    "\n",
    "summ = rows1+rows2+rows3+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df4 is not None:\n",
    "    for i in range(rows4):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows4, summ+rows4):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows4):\n",
    "        dataframe.loc[i]=0\n",
    "\n",
    "#dataframe.shape\n",
    "\n",
    "#For supplemental\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=2)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nsupplemental\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 ms, sys: 36 µs, total: 3.5 ms\n",
      "Wall time: 5.91 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "# 4. make class predictions for X_test_dtm\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1         2         3         4         5         6         7      \\\n",
      "0  0.012255  0.226727  0.012255  0.012255  0.004596  0.019915  0.003064   \n",
      "0  0.000809  0.007487  0.000051  0.000051  0.000051  0.000051  0.000051   \n",
      "\n",
      "      8         9         10       ...        17324     17325     17326  \\\n",
      "0  0.001532  0.015319  0.243578    ...     0.000051  0.000051  0.000051   \n",
      "0  0.000051  0.000708  0.000051    ...     0.000051  0.000051  0.000051   \n",
      "\n",
      "      17327     17328     17329     17330     17331     17332     17333  \n",
      "0  0.000051  0.000152  0.002681  0.000051  0.000101  0.000354  0.000051  \n",
      "0  0.000051  0.000152  0.002681  0.000051  0.000101  0.000354  0.000051  \n",
      "\n",
      "[2 rows x 17333 columns]\n",
      "\n",
      "Fulltext\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tempdf1 = pd.concat([df3,df1], axis =0)\n",
    "except:\n",
    "    tempdf1 = df3\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df4], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df5], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "summ = rows1+rows2+rows4+rows5+rows6\n",
    "\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df3 is not None:\n",
    "    for i in range(rows3):\n",
    "        dataframe.loc[i] = 1\n",
    "    for j in range(rows3, summ+rows3):\n",
    "        dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows3):\n",
    "        dataframe.loc[i]=0\n",
    "#dataframe.shape\n",
    "\n",
    "#For fulltext\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25, random_state = 5)\n",
    "print(X_test[:10])\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nFulltext\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.62 ms, total: 2.62 ms\n",
      "Wall time: 3.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k7-user0/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "# 4. make class predictions for X_test_dtm\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Related Content\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    tempdf1 = pd.concat([df5,df1], axis =0)\n",
    "    #print(\"try\")\n",
    "except:\n",
    "    tempdf1 = df5\n",
    "try:\n",
    "    tempdf2 = pd.concat([tempdf1,df2], axis = 0)\n",
    "except:\n",
    "    tempdf2 = tempdf1\n",
    "try:\n",
    "    tempdf3 = pd.concat([tempdf2,df3], axis =0)\n",
    "except:\n",
    "    tempdf3 = tempdf2\n",
    "try:\n",
    "    tempdf4 = pd.concat([tempdf3,df4], axis =0)\n",
    "except:\n",
    "    tempdf4 = tempdf3\n",
    "try:\n",
    "    finaldf = pd.concat([tempdf4,df6], axis =0)\n",
    "except:\n",
    "    finaldf = tempdf4\n",
    "\n",
    "index = finaldf.shape[0]\n",
    "#print(index)\n",
    "\n",
    "summ = rows1+rows2+rows3+rows4+rows6\n",
    "#print(summ)\n",
    "#print(rows5)\n",
    "dataframe = DataFrame(columns=(['not-content_or_not']))\n",
    "if df5 is not None:\n",
    "    #print(\"im in\")\n",
    "    if rows5 is 0:\n",
    "        for i in range(index):\n",
    "            dataframe.loc[i] = 0\n",
    "    else:\n",
    "        for i in range(rows5):\n",
    "            dataframe.loc[i] = 1\n",
    "        for j in range(rows5, summ+rows5):\n",
    "            dataframe.loc[j] = 0\n",
    "else:\n",
    "    for i in range(summ+rows5+1):\n",
    "        dataframe.loc[i]=0\n",
    "#print(dataframe)\n",
    "\n",
    "#For related content\n",
    "Y = dataframe\n",
    "\n",
    "X = finaldf\n",
    "X = X.fillna(X.mean())\n",
    "#print(X.shape)\n",
    "\n",
    "Y = np.ravel(Y)\n",
    "#Y\n",
    "Y=Y.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#print(X.shape)\n",
    "#print(Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state=4)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "expected = Y_test\n",
    "print(\"\\nRelated Content\")\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 0 ns, total: 11.4 ms\n",
      "Wall time: 10.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k7-user0/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 2. instantiate a Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "# 3. train the model \n",
    "# using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "%time nb.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "# 4. make class predictions for X_test_dtm\n",
    "Y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
